{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch import optim\n",
    "import random \n",
    "import sys\n",
    "from pytorch_transformers.tokenization_distilbert import DistilBertTokenizer\n",
    "from pytorch_transformers.modeling_distilbert import DistilBertModel\n",
    "from scipy.special import softmax\n",
    "import getopt\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def __init__(self, esz=1536, num_layers=5):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dense = [torch.nn.Linear(\n",
    "            esz, int(esz),\n",
    "        ).cuda() for i in range(num_layers)]\n",
    "        \n",
    "        self.relu = [torch.nn.ReLU().cuda() for i in range(num_layers)]\n",
    "        self.out = torch.nn.Linear(\n",
    "            int(esz), 2,\n",
    "        ).cuda()\n",
    "        \n",
    "        self.bn = torch.nn.BatchNorm1d(1).cuda()\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        for i in range(self.num_layers):\n",
    "            input = self.relu[i](self.dense[i](input.cuda()))\n",
    "        return self.bn(self.out(input))\n",
    "\n",
    "class Attention(torch.nn.Module):    \n",
    "    def __init__(self, esz=768, seq_len=20):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(\n",
    "            esz, 1\n",
    "        ).cuda()\n",
    "        self.relu = torch.nn.ReLU().cuda()\n",
    "        self.sm = torch.nn.Softmax().cuda()\n",
    "        self.attn = torch.nn.MultiheadAttention(esz, 8).cuda()\n",
    "        #self.bn = torch.nn.BatchNorm1d(seq_len).cuda()\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        #return self.sm(self.dense(input.cuda()).cuda()).cuda()\n",
    "        out, _ = self.attn(input.cuda(), input.cuda(), input.cuda())\n",
    "        #return self.bn(out)\n",
    "        return out\n",
    "    \n",
    "class ModelDataset():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.train_data = []\n",
    "        self.test_data = []\n",
    "\n",
    "        with open(\"inferences.csv\") as csvDataFile:\n",
    "            csvreader = csv.reader(csvDataFile, delimiter='\\t')\n",
    "            next(csvreader)\n",
    "            for context1, context2, utterance1, utterance2, inf1, inf2, inf3 in csvreader:\n",
    "                target = self.test_data if random.random() > 0.8 else self.train_data\n",
    "                target.append({\n",
    "                    \"context1\":context1,\n",
    "                    \"context2\":context2,\n",
    "                    \"utterance1\":utterance1,\n",
    "                    \"utterance2\":utterance2,\n",
    "                    \"inf1\":inf1,\n",
    "                    \"inf2\":inf2,\n",
    "                    \"inf3\":inf3,\n",
    "                })\n",
    "\n",
    "    def sample_train(self):\n",
    "        positive = random.choice(self.train_data)\n",
    "        while \"inf_random\" not in positive or positive[\"inf1\"] == positive[\"inf_random\"]:\n",
    "            negative = random.choice(self.train_data)\n",
    "            positive[\"inf_random\"] = negative[\"inf1\"]\n",
    "        return positive\n",
    "\n",
    "    def sample_test(self):\n",
    "        positive = random.choice(self.test_data)\n",
    "        while \"inf_random\" not in positive or positive[\"inf1\"] == positive[\"inf_random\"]:\n",
    "            negative = random.choice(self.train_data)\n",
    "            positive[\"inf_random\"] = negative[\"inf1\"]\n",
    "        return positive\n",
    "    \n",
    "class Model():\n",
    "    def __init__(self, tokenizer=None, encoder=None, lr=0.0005, esz=768, pad_len=20, model_name=None,path=None, bsz=10, save_steps=50):\n",
    "        self.save_steps = save_steps\n",
    "        self.model_name = model_name\n",
    "        self.bsz = bsz\n",
    "        self.dataset = ModelDataset()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.encoder = encoder\n",
    "        self.pad_len = pad_len\n",
    "        self.classifier = Classifier(esz=esz*2) \n",
    "        self.context_attention = Attention(esz=esz, seq_len=pad_len)\n",
    "        self.inference_attention = Attention(esz=esz, seq_len=pad_len)\n",
    "        self.utterance_attention = Attention(esz=esz, seq_len=pad_len)\n",
    "        self.optims = {\n",
    "            'classifier': optim.Adam(self.classifier.parameters(), lr=lr),\n",
    "            'context_attention': optim.Adam(self.context_attention.parameters(), lr=lr),\n",
    "            'inference_attention': optim.Adam(self.inference_attention.parameters(), lr=lr),\n",
    "            'utterance_attention': optim.Adam(self.utterance_attention.parameters(), lr=lr),\n",
    "        }\n",
    "        self.classifier_scheduler = torch.optim.lr_scheduler.StepLR(self.optims[\"classifier\"], 0.9)\n",
    "        self.context_attention_scheduler = torch.optim.lr_scheduler.StepLR(self.optims[\"context_attention\"], 0.9)\n",
    "        self.inference_attention_scheduler = torch.optim.lr_scheduler.StepLR(self.optims[\"inference_attention\"], 0.9)\n",
    "        self.utterance_attention_scheduler = torch.optim.lr_scheduler.StepLR(self.optims[\"utterance_attention\"], 0.9)\n",
    "        \n",
    "        if path is not None:\n",
    "            self.classifier.load_state_dict(torch.load(path + \"/\" + model_name + \"_classifier.model\"))\n",
    "            self.context_attention.load_state_dict(torch.load(path + \"/\" + model_name + \"_context_attention.model\"))\n",
    "            self.inference_attention.load_state_dict(torch.load(path + \"/\" + model_name + \"_inference_attention.model\"))\n",
    "            self.utterance_attention.load_state_dict(torch.load(path + \"/\" + model_name + \"_utterance_attention.model\"))\n",
    "        \n",
    "        self.loss = 0\n",
    "        self.step = 0\n",
    "        self.c_loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    def update_params(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "            \n",
    "    def get_and_attend_context(self, embedded):\n",
    "        context_attention_mask1 = self.context_attention(embedded[\"context1\"].cuda())\n",
    "        context_attention_mask2 = self.context_attention(embedded[\"context2\"].cuda())\n",
    "        context = torch.sum((context_attention_mask1 * embedded[\"context1\"].cuda()) + (context_attention_mask2 * embedded[\"context2\"].cuda()), 1)\n",
    "        return context\n",
    "    \n",
    "    def attend_inference(self, inf):\n",
    "        inference_attention_mask = self.inference_attention(inf.cuda())\n",
    "        return torch.sum(inference_attention_mask * inf.cuda(), 1).cuda()\n",
    "        #return inf.mean(1)\n",
    "\n",
    "    def attend_utterance(self, utterance):\n",
    "        utterance_attention_mask = self.utterance_attention(utterance.cuda())\n",
    "        return torch.sum(utterance_attention_mask * utterance.cuda(), 1).cuda()\n",
    "        #return utterance.mean(1)\n",
    "    \n",
    "    def merge_utterance_with_inference_and_context(self, context, utterance, inference):\n",
    "        #return torch.cat([context,utterance,inference], 1)\n",
    "        return torch.cat([utterance,inference], 1)\n",
    "        \n",
    "    def eval_step(self):\n",
    "        self.classifier.eval()\n",
    "        self.context_attention.eval()\n",
    "        self.inference_attention.eval()\n",
    "        \n",
    "        accuracy = 0\n",
    "        num_steps = 10\n",
    "        for _ in range(num_steps):\n",
    "            xs = self.dataset.sample_test()\n",
    "            #xs = sample_train()\n",
    "            print(\"Sample: %s\" % xs[\"utterance1\"])\n",
    "            print(\"Positive Inference 1: %s\" % xs[\"inf1\"])\n",
    "            embedded = self.embed_sample(xs)\n",
    "            \n",
    "            context = self.get_and_attend_context(embedded).cuda()\n",
    "            inf1 = self.attend_inference(embedded[\"inf1\"].cuda()).cuda()\n",
    "            utterance1 = self.attend_utterance(embedded[\"utterance1\"].cuda()).cuda()\n",
    "            merged_positive = self.merge_utterance_with_inference_and_context(context, utterance1, inf1).cuda().unsqueeze(0)\n",
    "            pred = self.classifier(merged_positive) .cuda()\n",
    "            print(pred)\n",
    "            pred = torch.argmax(pred[0], 1)\n",
    "            #if pred.item() == 0:\n",
    "                #print(\"Inference does not follow\")\n",
    "                #accuracy += .append(0)\n",
    "            if pred.item() == 1:\n",
    "                #print(\"Inference follows\")\n",
    "                accuracy += 1\n",
    "\n",
    "            inf_random = self.attend_inference(embedded[\"inf_random\"]).cuda()\n",
    "            merged_negative = self.merge_utterance_with_inference_and_context(context, utterance1, inf_random).cuda().unsqueeze(0)\n",
    "\n",
    "            print(\"Negative Inference 1: %s\" % xs[\"inf_random\"])\n",
    "            pred = self.classifier(merged_negative).cuda() \n",
    "            print(pred)\n",
    "            pred = torch.argmax(pred[0], 1)\n",
    "            \n",
    "            if pred.item() == 0:\n",
    "            #    print(\"Inference does not follow\")\n",
    "                #accuracy.append(1)\n",
    "                accuracy += 1\n",
    "            #else:\n",
    "                #accuracy.append(0)\n",
    "            #    print(\"Inference follows\")\n",
    "\n",
    "            #context = self.get_and_attend_context(embedded)\n",
    "            #inp = self.attend_inference_and_merge_context(embedded[\"inf1\"], context)\n",
    "        print(\"Accuracy : %f\" % (accuracy / (num_steps * 2)))\n",
    "        print(\"####################\")\n",
    "                \n",
    "    def embed_sample(self, xs):\n",
    "        embedded = {}\n",
    "        for k in [\"context1\",\"context2\",\"utterance1\",\"utterance2\",\"inf1\",\"inf2\",\"inf3\",\"inf_random\"]:\n",
    "            if k in xs and len(xs[k]) > 0:\n",
    "                tokens = self.tokenizer.encode(xs[k])\n",
    "                padded = torch.full((1, self.pad_len), self.tokenizer.pad_token_id, dtype=torch.long)\n",
    "                padded[0,:len(tokens)] = torch.LongTensor([tokens])\n",
    "                embedded[k] = self.encoder(padded)[0]\n",
    "        return embedded\n",
    "        \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.classifier.train()\n",
    "        self.context_attention.train()\n",
    "        self.inference_attention.train()\n",
    "        batch_xs = []\n",
    "        batch_ys = []\n",
    "        for _ in range(self.bsz):\n",
    "            xs = self.dataset.sample_train()\n",
    "            #print(xs)\n",
    "            embedded = self.embed_sample(xs)\n",
    "            context = self.get_and_attend_context(embedded).cuda()\n",
    "            inf1 = self.attend_inference(embedded[\"inf1\"]).cuda()\n",
    "            utterance1 = self.attend_utterance(embedded[\"utterance1\"]).cuda()\n",
    "            merged_positive = self.merge_utterance_with_inference_and_context(context, utterance1, inf1).cuda()\n",
    "            inf_random = self.attend_inference(embedded[\"inf_random\"]).cuda()\n",
    "            merged_negative = self.merge_utterance_with_inference_and_context(context, utterance1, inf_random).cuda()\n",
    "            batch_xs.append(merged_positive)\n",
    "            batch_xs.append(merged_negative)\n",
    "            batch_ys.append([1])\n",
    "            batch_ys.append([0])\n",
    "        inp = torch.cat(batch_xs, 0).unsqueeze(1).cuda()\n",
    "        \n",
    "            #if \"inf2\" in embedded:\n",
    "            #    inf2 = self.attend_inference_and_merge_context(embedded[\"inf2\"], context)\n",
    "            #    inp = torch.cat([inp, inf2, inf_random], 0)\n",
    "            #    outs += [1,0]\n",
    "            #    if \"inf3\" in embedded:\n",
    "            #        inf3 = self.attend_inference_and_merge_context(embedded[\"inf3\"], context)\n",
    "            #        inp = torch.cat([inp, inf3, inf_random], 0)\n",
    "            #        outs += [1,0]\n",
    "        \n",
    "        outs = torch.LongTensor(batch_ys).cuda()\n",
    "        pred = self.classifier(inp.cuda()).cuda()\n",
    "        loss = self.c_loss(torch.transpose(pred, 1, 2), outs)\n",
    "\n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % self.save_steps == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.eval_step()\n",
    "            self.classifier_scheduler.step()\n",
    "            self.context_attention_scheduler.step()\n",
    "            self.inference_attention_scheduler.step()\n",
    "            self.utterance_attention_scheduler.step()\n",
    "            torch.save(self.classifier.state_dict(), self.model_name + \"_classifier.model\")\n",
    "            torch.save(self.context_attention.state_dict(), self.model_name + \"_context_attention.model\")\n",
    "            torch.save(self.inference_attention.state_dict(), self.model_name + \"_inference_attention.model\")\n",
    "            torch.save(self.utterance_attention.state_dict(), self.model_name + \"_utterance_attention.model\")\n",
    "\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "    \n",
    "    def classify(self, utterance, condition, context):\n",
    "        embedded = self.embed_sample({\n",
    "            \"context1\":context,\n",
    "            \"context2\":\"NULL\",\n",
    "            \"utterance1\":utterance,\n",
    "            \"inf1\":condition\n",
    "        })\n",
    "        \n",
    "        context = self.get_and_attend_context(embedded).cuda()\n",
    "        inf1 = self.attend_inference(embedded[\"inf1\"]).cuda()\n",
    "        utterance1 = self.attend_utterance(embedded[\"utterance1\"]).cuda()\n",
    "        inp = self.merge_utterance_with_inference_and_context(context, utterance1, inf1).cuda()\n",
    "        \n",
    "        pred = self.classifier(inp.cuda()).cuda()\n",
    "        return pred\n",
    "        \n",
    "        \n",
    "        \n",
    "class SequenceModelDataset():\n",
    "    def __init__(self):\n",
    "        self.train_data = []\n",
    "        self.test_data = []\n",
    "\n",
    "        with open(\"sequences.csv\") as csvDataFile:\n",
    "            csvreader = csv.reader(csvDataFile, delimiter='\\t')\n",
    "            next(csvreader)\n",
    "            for utterance, context, response, _, _, _, _ in csvreader:\n",
    "                target = test_data if random.random() > 0.8 else train_data\n",
    "                target.append({\n",
    "                    \"utterance\":utterance,\n",
    "                    \"context\":context,\n",
    "                    \"response\":response,\n",
    "                })\n",
    "\n",
    "    def sample_train():\n",
    "        positive = random.choice(self.train_data)\n",
    "        while \"response_random\" not in positive or positive[\"response\"] == positive[\"response_random\"]:\n",
    "            negative = random.choice(train_data)\n",
    "            positive[\"response_random\"] = negative[\"response\"]\n",
    "        return positive\n",
    "\n",
    "    def sample_test():\n",
    "        positive = random.choice(self.test_data)\n",
    "        while \"response_random\" not in positive or positive[\"response\"] == positive[\"response_random\"]:\n",
    "            negative = random.choice(train_data)\n",
    "            positive[\"response_random\"] = negative[\"response\"]\n",
    "        return positive\n",
    "\n",
    "class SequenceModel(Model):\n",
    "    def __init__(self, tokenizer=None, encoder=None, lr=0.0001, esz=768, pad_len=30,path=None, model_name=None, save_steps=50):\n",
    "        super().__init__(tokenizer=tokenizer, encoder=encoder, lr=lr, esz=esz, pad_len=pad_len,path=path,model_name=model_name, save_steps=save_steps)\n",
    "                    \n",
    "    def get_and_attend_context(self, embedded):\n",
    "        context_attention_mask = self.context_attention(embedded[\"context\"])\n",
    "        return context_attention_mask.cuda() * embedded[\"context\"].cuda()\n",
    "    \n",
    "    def embed_sample(self, xs):\n",
    "        embedded = {}\n",
    "        for k in [\"utterance\",\"context\",\"response\",  \"response_random\"]:\n",
    "            if k in xs and len(xs[k]) > 0:\n",
    "                tokens = self.tokenizer.encode(xs[k])\n",
    "                padded = torch.full((1, self.pad_len), self.tokenizer.pad_token_id, dtype=torch.long)\n",
    "                padded[0,:len(tokens)] = torch.LongTensor([tokens])\n",
    "                embedded[k] = self.encoder(padded)[0]\n",
    "        return embedded\n",
    "    \n",
    "    def eval_step(self):\n",
    "        self.classifier.eval()\n",
    "        self.context_attention.eval()\n",
    "        self.inference_attention.eval()\n",
    "        \n",
    "        accuracy = 0\n",
    "        num_steps = 10\n",
    "        for _ in range(num_steps):\n",
    "            xs = sample_test()\n",
    "            print(\"Utterance: %s\" % xs[\"utterance\"])\n",
    "            print(\"Positive response: %s\" % xs[\"response\"])\n",
    "            embedded = self.embed_sample(xs)\n",
    "            \n",
    "            context = SequenceModel.get_and_attend_context(self, embedded)\n",
    "            utterance = self.attend_utterance(embedded[\"utterance\"])\n",
    "            response = self.attend_inference(embedded[\"response\"])\n",
    "            merged_positive = self.merge_utterance_with_inference_and_context(context, utterance, response)\n",
    "\n",
    "            pred = self.classifier(merged_positive) \n",
    "            #print(pred)\n",
    "            pred = torch.argmax(pred, 1)\n",
    "            #if pred.item() == 0:\n",
    "                #print(\"Inference does not follow\")\n",
    "                #accuracy += .append(0)\n",
    "            if pred.item() == 1:\n",
    "                #print(\"Inference follows\")\n",
    "                accuracy += 1\n",
    "\n",
    "            response_random = self.attend_inference(embedded[\"response_random\"])\n",
    "            merged_negative = self.merge_utterance_with_inference_and_context(context, utterance, response_random)\n",
    "\n",
    "            pred = self.classifier(merged_negative) \n",
    "            \n",
    "            pred = torch.argmax(pred, 1)\n",
    "            print(\"Negative Inference 1: %s\" % xs[\"response_random\"])\n",
    "            if pred.item() == 0:\n",
    "            #    print(\"Inference does not follow\")\n",
    "                #accuracy.append(1)\n",
    "                accuracy += 1\n",
    "            #else:\n",
    "                #accuracy.append(0)\n",
    "            #    print(\"Inference follows\")\n",
    "            #print(pred)\n",
    "            #context = self.get_and_attend_context(embedded)\n",
    "            #inp = self.attend_inference_and_merge_context(embedded[\"inf1\"], context)\n",
    "        print(\"Accuracy : %f\" % (accuracy / (num_steps * 2)))\n",
    "                        \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.classifier.train()\n",
    "        self.context_attention.train()\n",
    "        self.inference_attention.train()\n",
    "\n",
    "        xs = super().sample_train()\n",
    "        \n",
    "        embedded = self.embed_sample(xs)\n",
    "        \n",
    "        context = self.get_and_attend_context(embedded)\n",
    "        response = self.attend_inference(embedded[\"response\"])\n",
    "        utterance = self.attend_inference(embedded[\"utterance\"])\n",
    "        merged_positive = self.merge_utterance_with_inference_and_context(context, utterance, response)\n",
    "\n",
    "        response_random = self.attend_inference(embedded[\"response_random\"])\n",
    "        merged_negative = self.merge_utterance_with_inference_and_context(context, utterance, response_random)\n",
    "        inp = torch.cat([merged_positive, merged_negative], 0).unsqueeze(1)\n",
    "        outs = [[1],[0]]\n",
    "        \n",
    "        outs = torch.cuda.LongTensor(outs)\n",
    "\n",
    "        pred = self.classifier(inp)\n",
    "\n",
    "        loss = self.c_loss(torch.transpose(pred, 1, 2), outs)\n",
    "\n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % self.save_steps == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.eval_step()\n",
    "            torch.save(self.classifier.state_dict(), \"classifier_seq.model\")\n",
    "            torch.save(self.context_attention.state_dict(), \"context_attention_seq.model\")\n",
    "            torch.save(self.inference_attention.state_dict(), \"inference_attention_seq.model\")\n",
    "            torch.save(self.utterance_attention.state_dict(), \"utterance_attention_seq.model\")\n",
    "            self.classifier_scheduler.step()\n",
    "            self.context_attention_scheduler.step()\n",
    "            self.inference_attention_scheduler.step()\n",
    "            self.utterance_attention_scheduler.step()\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "    \n",
    "    def classify(self, utterance, context, response):\n",
    "        \"\"\"Inference step to determine whether response is coherent given utterance\"\"\"\n",
    "        self.classifier.eval()\n",
    "        self.context_attention.eval()\n",
    "        self.inference_attention.eval()\n",
    "        \n",
    "        embedded = self.embed_sample({\"utterance\":utterance, \"response\":response, \"context\":context})\n",
    "        \n",
    "        context = self.get_and_attend_context(embedded)\n",
    "        response = self.attend_inference(embedded[\"response\"])\n",
    "        utterance = self.attend_inference(embedded[\"utterance\"])\n",
    "        merged = self.merge_utterance_with_inference_and_context(context, utterance, response)\n",
    "        pred = self.classifier(merged)\n",
    "        return softmax(pred[0].cpu().detach().numpy())[1].item()\n",
    "\n",
    "class RuntimeModel():\n",
    "    def __init__(self, classifier_model, seq_model):\n",
    "        self.candidates = []\n",
    "        self.history = []\n",
    "        \n",
    "        self.step = 0\n",
    "        self.done = False\n",
    "        self.classifier_model = classifier_model\n",
    "        self.seq_model = seq_model\n",
    "        self.conditions = []\n",
    "        \n",
    "        with open(\"runtime.tsv\") as csvDataFile:\n",
    "            csvreader = csv.reader(csvDataFile, delimiter='\\t')\n",
    "            next(csvreader)\n",
    "            for candidate, condition, example1, example2, hint1, hint2 in csvreader:\n",
    "                self.candidates.append({\n",
    "                    \"candidate\":candidate,\n",
    "                    \"condition\":condition,\n",
    "                    \"example1\":example1,\n",
    "                    \"example2\":example2,\n",
    "                    \"hint1\":hint1,\n",
    "                    \"hint2\":hint2,\n",
    "                })\n",
    "    \n",
    "    def next(self):\n",
    "        if self.step == 0:\n",
    "            for index, x in enumerate(self.candidates):\n",
    "                if x[\"condition\"] == \"NULL\":\n",
    "                    self.history.append(x[\"candidate\"])\n",
    "                    self.candidates.pop(index)\n",
    "                    return x[\"candidate\"]\n",
    "            raise Exception()\n",
    "        \n",
    "        idx_max = -1\n",
    "        c_max = -1\n",
    "        for index, x in enumerate(self.candidates):\n",
    "            classification = self.seq_model.classify(x[\"candidate\"], x[\"condition\"], self.history[-1])\n",
    "            if classification > c_max:\n",
    "                c_max = classification\n",
    "                idx_max = index\n",
    "                \n",
    "        return self.candidates[idx_max].candidate\n",
    "        \n",
    "    def process(self, inp, threshold=0.5):\n",
    "        max_coherence_score = -1\n",
    "        max_coherence_index = -1\n",
    "        for index, x in enumerate(self.candidates):\n",
    "#                    def classify(self, utterance, condition, context):\n",
    "\n",
    "            score = self.classifier_model.classify(inp, x[\"condition\"], self.history[-1])\n",
    "            score = softmax(score.cpu().detach().numpy())\n",
    "            print(score)\n",
    "            print(\"Condition Classification Score for %s : %f\" % (x[\"condition\"], score[0][1]))\n",
    "            \n",
    "            if score[0,1] > threshold:\n",
    "                self.conditions.append(x[\"condition\"])\n",
    "                #def classify(self, utterance, context, response):\n",
    "                coherence_score = self.seq_model.classify(inp, self.history[-1], x[\"candidate\"])\n",
    "                print(\"Coherence Score for %s : %f\" % (x[\"candidate\"], coherence_score))\n",
    "                if coherence_score > max_coherence_score:\n",
    "                    max_coherence_score = coherence_score\n",
    "                    max_coherence_index = index\n",
    "        if max_coherence_score == -1:\n",
    "            raise Exception()\n",
    "        return self.candidates[max_coherence_index]\n",
    "        \n",
    "def run_with_opts(opts):\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    special_tokens_dict = {'additional_special_tokens': ['<PLH>', '<s>','</s>']}\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "    encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    for param in encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    pad_token = tokenizer.pad_token\n",
    "        \n",
    "    if opts[\"train_classifier\"]:\n",
    "        model = Model(tokenizer=tokenizer, encoder=encoder,model_name=\"classifier\")\n",
    "        for i in range(1000):\n",
    "            model.train_step()\n",
    "    else:\n",
    "        model = Model(path=opts[\"model_dir\"], tokenizer=tokenizer, encoder=encoder)\n",
    "    \n",
    "    \n",
    "    if opts[\"train_seq\"]:\n",
    "        seq_model = SequenceModel(tokenizer=tokenizer, encoder=encoder,model_name=\"sequence\")\n",
    "        for i in range(1000):\n",
    "            seq_model.train_step()\n",
    "    else:\n",
    "        seq_model = SequenceModel(path=opts[\"model_dir\"], tokenizer=tokenizer, encoder=encoder)\n",
    "        \n",
    "    runtime_model = RuntimeModel(model, seq_model)\n",
    "    \n",
    "    if opts[\"interactive\"]:\n",
    "        while runtime_model.done is False:\n",
    "            print(runtime_model.next())\n",
    "            inp = input(\"> \")\n",
    "            runtime_model.process(inp)\n",
    "    return runtime_model\n",
    "    \n",
    "def main():\n",
    "    # parse command line options\n",
    "    try:\n",
    "        opts, args = getopt.getopt(sys.argv[1:], \"h\", [\"help\"])\n",
    "    except Exception as msg:\n",
    "        print(msg)\n",
    "        print(\"for help use --help\")\n",
    "        sys.exit(2)\n",
    "    \n",
    "    opts = {\n",
    "        \"train_classifier\":False,\n",
    "        \"classifier_path\":None,\n",
    "        \"train_seq\":False,\n",
    "        \"seq_path\":None\n",
    "    }\n",
    "    \n",
    "    # process options\n",
    "    for o, a in opts:\n",
    "        if o in (\"-h\", \"--help\"):\n",
    "            print(__doc__)\n",
    "            sys.exit(0)\n",
    "            continue\n",
    "        if o is \"--train-classifier\":\n",
    "            opts[\"train_classifier\"] = true\n",
    "        if o is \"--train-seq\" :\n",
    "            opts[\"train_seq\"] = true\n",
    "        if o is \"--model-dir\":\n",
    "            opts[\"model_dir\"] = a\n",
    "        \n",
    "    run_with_opts(opts)\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "tensor(0.7496, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6694, -0.7833]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-1.4414, -0.5743]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.0513,  0.5419]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.3805, 0.4403]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6694, -0.7833]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-1.4414, -0.5743]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.0513,  0.5419]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.3805, 0.4403]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.7832, -0.7785]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.7231, -0.7233]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6694, -0.7833]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-1.4414, -0.5743]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.0955,  0.2285]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0997, 0.1238]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.2954, 0.4546]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1691, 0.3964]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.1502, -0.1811]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2977, -0.1649]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.1290, -0.3710]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5251, -0.5594]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.350000\n",
      "####################\n",
      "100\n",
      "tensor(0.4800, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.3390, -0.2547]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5024, -0.7763]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[0.8612, 0.6972]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.6068, 1.1889]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.2854,  0.5159]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[-0.0402,  0.2390]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.4502, 0.9318]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1867, 0.8285]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.2854,  0.5159]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[-0.0402,  0.2390]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.2854,  0.5159]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[-0.0402,  0.2390]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[0.8612, 0.6972]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.6068, 1.1889]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0786, 0.7492]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[0.9447, 0.6642]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.0981, -0.0640]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2786,  0.0390]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[0.8612, 0.6972]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.6068, 1.1889]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.450000\n",
      "####################\n",
      "150\n",
      "tensor(0.4208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3092, -0.8646]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3275, -1.0980]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[1.0134, 0.6661]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.6965, 1.2513]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.0767, -0.3036]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.3510, -0.0753]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6680, -1.0727]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.6375, -0.5300]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0127, 0.7599]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1066, 0.5401]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.8406, -0.7918]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6693, -0.7780]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2815,  1.1170]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.7718, 0.5094]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-1.0231, -1.7520]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4855, -1.5277]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.5006, 1.0025]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1727, 0.8923]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6680, -1.0727]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.6375, -0.5300]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.450000\n",
      "####################\n",
      "200\n",
      "tensor(0.3956, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[ 0.0005, -0.1775]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2482,  0.0332]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[ 0.0005, -0.1775]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2482,  0.0332]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0877, 0.7941]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1007, 0.5907]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.2814,  0.4837]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0218, 0.0969]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.2814,  0.4837]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0218, 0.0969]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.5351, 1.0304]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.2339, 0.9309]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.2814,  0.4837]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0218, 0.0969]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.2503, -0.3331]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.4428, -0.8347]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.8684, -1.5140]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.2898, -1.2955]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.7010, -0.6200]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.5404, -0.6067]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.500000\n",
      "####################\n",
      "250\n",
      "tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[1.0186, 0.6922]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.6927, 1.2804]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6697, -1.0527]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.6534, -0.5093]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0090, 0.7755]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1074, 0.5549]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.4940, 1.0334]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1673, 0.9255]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.3583, -0.4454]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5660, -0.9907]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3085, -0.8206]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3307, -1.0673]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2845,  1.1400]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.7791, 0.5163]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0090, 0.7755]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1074, 0.5549]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6697, -1.0527]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.6534, -0.5093]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3927,  0.4404]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[-0.0635,  0.0201]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.500000\n",
      "####################\n",
      "300\n",
      "tensor(0.4081, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3203,  0.5004]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0037, 0.0865]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2138,  1.1891]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8334, 0.5749]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0183, -0.2061]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2837,  0.0191]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.0183, -0.2061]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2837,  0.0191]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.9456, -1.6332]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.3950, -1.3990]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.2373, -0.7409]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.2592, -0.9838]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.5929, -0.9695]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5459, -0.4345]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0751, 0.8303]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1564, 0.6130]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2138,  1.1891]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8334, 0.5749]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.9456, -1.6332]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.3950, -1.3990]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.500000\n",
      "####################\n",
      "350\n",
      "tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.4872, 1.0507]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1462, 0.9380]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-1.1012, -1.8303]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.5777, -1.5819]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[-0.0191,  0.7815]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1273, 0.5512]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.3254,  1.1619]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.7849, 0.5108]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.3254,  1.1619]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.7849, 0.5108]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.7273, -1.1265]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.7979, -0.5594]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.1181, -0.3172]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.3995, -0.0785]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-1.1012, -1.8303]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.5777, -1.5819]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3503, -0.8842]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3736, -1.1417]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3503, -0.8842]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3736, -1.1417]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.550000\n",
      "####################\n",
      "400\n",
      "tensor(0.3993, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.7963, -0.7101]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6299, -0.6964]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2612,  1.0959]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.7519, 0.5017]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6279, -0.9923]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5173, -0.4748]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6279, -0.9923]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5173, -0.4748]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.4802, 0.9944]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1691, 0.8916]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6279, -0.9923]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5173, -0.4748]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.3315, -0.4139]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5293, -0.9333]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[0.9799, 0.6695]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.6695, 1.2297]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6279, -0.9923]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5173, -0.4748]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.0721, -0.2537]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.3288, -0.0359]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.300000\n",
      "####################\n",
      "450\n",
      "tensor(0.3951, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.5768, 1.1312]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.2414, 1.0204]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.2984, -0.3872]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5116, -0.9472]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.2471, -0.7723]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.2700, -1.0257]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.7995, -0.7065]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6201, -0.6917]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.7995, -0.7065]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6201, -0.6917]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0787, 0.8664]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.2066, 0.6398]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2226,  1.2406]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8697, 0.6000]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3337,  0.5223]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0043, 0.0906]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I am a doctor.\n",
      "Positive Inference 1: You work in health.\n",
      "tensor([[[-0.0186, -0.2145]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for an engineering company.\n",
      "tensor([[[-0.2955,  0.0203]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3337,  0.5223]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0043, 0.0906]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.650000\n",
      "####################\n",
      "500\n",
      "tensor(0.4015, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.2573, -0.7552]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.2790, -0.9954]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3394,  0.4721]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[-0.0190,  0.0628]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2341,  1.1530]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8014, 0.5457]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6089, -0.9813]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5400, -0.4524]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2341,  1.1530]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8014, 0.5457]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.3060, -0.3901]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5081, -0.9210]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0515, 0.7983]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1207, 0.5834]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6089, -0.9813]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5400, -0.4524]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3394,  0.4721]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[-0.0190,  0.0628]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.9576, -1.6376]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4020, -1.4060]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.550000\n",
      "####################\n",
      "550\n",
      "tensor(0.4056, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-1.0343, -1.7409]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4961, -1.5002]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.5051, 1.0512]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.1746, 0.9421]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.8508, -0.7592]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6740, -0.7446]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3066, -0.8240]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3291, -1.0736]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.0343, -1.7409]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4961, -1.5002]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.3571, -0.4446]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5671, -0.9963]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3066, -0.8240]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3291, -1.0736]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.8508, -0.7592]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6740, -0.7446]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.3066, -0.8240]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.3291, -1.0736]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.6719, -1.0589]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.6788, -0.5092]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.550000\n",
      "####################\n",
      "600\n",
      "tensor(0.4127, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.9515, -1.6389]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4007, -1.4047]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.5463, 1.0776]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.2248, 0.9714]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.2926, -0.3777]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.4969, -0.9144]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.2434, -0.7468]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.2653, -0.9896]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[-0.5989, -0.9754]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: When you were at university, you had at least 10 hours of classes.\n",
      "tensor([[[-2.5513, -0.4406]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.2926, -0.3777]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.4969, -0.9144]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2199,  1.1825]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8270, 0.5686]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0689, 0.8239]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.1499, 0.6066]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.2926, -0.3777]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.4969, -0.9144]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Winter.\n",
      "Positive Inference 1: Your favourite season is winter.\n",
      "tensor([[[-0.2434, -0.7468]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You play an offensive position in basketball.\n",
      "tensor([[[-0.2653, -0.9896]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.550000\n",
      "####################\n",
      "650\n",
      "tensor(0.4044, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Sample: Icecream.\n",
      "Positive Inference 1: You like eating icecream.\n",
      "tensor([[[-0.8013, -0.7081]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: Your favourite season is summer.\n",
      "tensor([[[-0.6215, -0.6933]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You have seen some musicals.\n",
      "tensor([[[1.1187, 0.7831]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You write software.\n",
      "tensor([[[0.7831, 1.3887]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3343,  0.5239]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0045, 0.0910]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: Your favourite food is icecream.\n",
      "tensor([[[-0.3343,  0.5239]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You run a manufacturing company.\n",
      "tensor([[[0.0045, 0.0910]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I play basketball\n",
      "Positive Inference 1: You play basketball.\n",
      "tensor([[[-0.2990, -0.3880]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You regularly read the newspaper on the weekend.\n",
      "tensor([[[-0.5127, -0.9494]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You hate your job.\n",
      "tensor([[[0.5785, 1.1343]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read around 10 books last year.\n",
      "tensor([[[0.2422, 1.0232]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No, I don't know how to make curry.\n",
      "Positive Inference 1: You don't know how to make curry.\n",
      "tensor([[[-0.2229,  1.2441]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You read more than three books per year.\n",
      "tensor([[[0.8722, 0.6018]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.9882, -1.7073]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4581, -1.4623]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[[0.0791, 0.8689]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You work for the government.\n",
      "tensor([[[1.2099, 0.6416]]], device='cuda:0', grad_fn=<CudnnBatchNormBackward>)\n",
      "Sample: No.\n",
      "Positive Inference 1: You do not own a car.\n",
      "tensor([[[-0.9882, -1.7073]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Negative Inference 1: You don't know how to drive.\n",
      "tensor([[[-1.4581, -1.4623]]], device='cuda:0',\n",
      "       grad_fn=<CudnnBatchNormBackward>)\n",
      "Accuracy : 0.600000\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "model = run_with_opts({\"model_dir\":\"./\", \"train_classifier\":True, \"train_seq\":True, \"interactive\":False})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = run_with_opts({\"model_dir\":\"./\", \"train_classifier\":False, \"train_seq\":False, \"interactive\":False})\n",
    "print(model.next())\n",
    "model.process(\"I play tennis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
