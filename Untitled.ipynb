{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import torch\n",
    "from torch import optim\n",
    "import random \n",
    "from pytorch_transformers.tokenization_distilbert import DistilBertTokenizer\n",
    "from pytorch_transformers.modeling_distilbert import DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "special_tokens_dict = {'additional_special_tokens': ['<PLH>', '<s>','</s>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "pad_token = tokenizer.pad_token\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "with open(\"C:\\\\Users\\\\nickh\\\\OneDrive\\\\Desktop\\\\inferences.csv\") as csvDataFile:\n",
    "    csvreader = csv.reader(csvDataFile, delimiter='\\t')\n",
    "    next(csvreader)\n",
    "    for context1, context2, sample1, sample2, inf1, inf2, inf3, inf4 in csvreader:\n",
    "        target = test_data if random.random() > 0.8 else train_data\n",
    "        target.append({\n",
    "            \"context1\":context1,\n",
    "            \"context2\":context2,\n",
    "            \"sample1\":sample1,\n",
    "            \"sample2\":sample2,\n",
    "            \"inf1\":inf1,\n",
    "            \"inf2\":inf2,\n",
    "            \"inf3\":inf3,\n",
    "        })\n",
    "\n",
    "def sample_train():\n",
    "    positive = random.choice(train_data)\n",
    "    while \"inf_random\" not in positive or positive[\"inf1\"] == positive[\"inf_random\"]:\n",
    "        negative = random.choice(train_data)\n",
    "        positive[\"inf_random\"] = negative[\"inf1\"]\n",
    "    return positive\n",
    "\n",
    "def sample_test():\n",
    "    positive = random.choice(test_data)\n",
    "    while \"inf_random\" not in positive or positive[\"inf1\"] == positive[\"inf_random\"]:\n",
    "        negative = random.choice(train_data)\n",
    "        positive[\"inf_random\"] = negative[\"inf1\"]\n",
    "    return positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "tensor(0.1039, grad_fn=<DivBackward0>)\n",
      "Sample: I am a lawyer.\n",
      "Positive Inference 1: You are a lawyer.\n",
      "tensor([[ 0.9206, -0.2482]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You own your own business.\n",
      "tensor([[ 1.1075, -0.2528]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[1.6185, 0.3185]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[ 1.6910, -0.1970]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am a lawyer.\n",
      "Positive Inference 1: You are a lawyer.\n",
      "tensor([[ 0.9206, -0.2482]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You own your own business.\n",
      "tensor([[ 1.1075, -0.2528]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 1.0806, -0.6793]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[ 1.1106, -0.5593]], grad_fn=<AddmmBackward>)\n",
      "Sample: Three\n",
      "Positive Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[ 1.1523, -0.4415]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You really like the springtime.\n",
      "tensor([[ 0.9155, -0.6252]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 1.0806, -0.6793]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[ 1.1106, -0.5593]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 1.0806, -0.6793]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[ 1.1106, -0.5593]], grad_fn=<AddmmBackward>)\n",
      "Sample: I enjoy reading, I read at least three books per year.\n",
      "Positive Inference 1: You like to read.\n",
      "tensor([[ 1.8390, -0.1080]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You cook regularly.\n",
      "tensor([[ 1.6720, -0.1062]], grad_fn=<AddmmBackward>)\n",
      "Sample: I play at least three times in a week\n",
      "Positive Inference 1: You play sport at least three times per week.\n",
      "tensor([[ 1.5070, -0.1512]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are an engineer.\n",
      "tensor([[ 1.9451, -0.1652]], grad_fn=<AddmmBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: You like to eat icecream.\n",
      "tensor([[ 1.5364, -0.2570]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You play sport at least three times per week.\n",
      "tensor([[ 1.5852, -0.2060]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.500000\n",
      "####################\n",
      "10\n",
      "tensor(0.0817, grad_fn=<DivBackward0>)\n",
      "Sample: One\n",
      "Positive Inference 1: You think there is one player in a tennis match.\n",
      "tensor([[-0.6759,  1.4510]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to read.\n",
      "tensor([[-0.2576,  1.4896]], grad_fn=<AddmmBackward>)\n",
      "Sample: I used to play piano when I was a kid.\n",
      "Positive Inference 1: You don't play an instrument.\n",
      "tensor([[-0.1796,  1.2088]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.1519, 0.9338]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[-0.6710,  1.1546]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[-0.6529,  1.2772]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[-0.4513,  1.4163]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[0.2991, 1.2289]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[-0.6710,  1.1546]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[-0.6529,  1.2772]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You like musicals.\n",
      "tensor([[0.2759, 0.9455]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[0.2808, 0.7657]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.0303,  1.7294]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[0.2021, 1.1166]], grad_fn=<AddmmBackward>)\n",
      "Sample: I like to read the newspaper.\n",
      "Positive Inference 1: On the weekend, you like to read the newspaper.\n",
      "tensor([[-0.2098,  1.1702]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You play the power forward position in basketball.\n",
      "tensor([[-0.5343,  1.2337]], grad_fn=<AddmmBackward>)\n",
      "Sample: Pizza.\n",
      "Positive Inference 1: Your favourite food is pizza.\n",
      "tensor([[-0.6326,  1.8950]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: On the weekend, you like to read the newspaper.\n",
      "tensor([[0.2221, 1.3675]], grad_fn=<AddmmBackward>)\n",
      "Sample: House music.\n",
      "Positive Inference 1: Your favourite style of music is house music.\n",
      "tensor([[-0.4064,  1.5767]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[-0.2360,  1.4373]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.500000\n",
      "####################\n",
      "15\n",
      "tensor(0.0674, grad_fn=<DivBackward0>)\n",
      "Sample: No, I don't like it.\n",
      "Positive Inference 1: You don't like your job.\n",
      "tensor([[1.6394, 0.1741]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[ 1.7288, -0.3211]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[0.5993, 0.3809]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[ 1.5848, -0.0533]], grad_fn=<AddmmBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You do not like musicals.\n",
      "tensor([[ 0.9493, -0.4015]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 0.7173, -0.0580]], grad_fn=<AddmmBackward>)\n",
      "Sample: I play at least three times in a week\n",
      "Positive Inference 1: You play sport at least three times per week.\n",
      "tensor([[0.9439, 0.4020]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are an engineer.\n",
      "tensor([[1.6069, 0.1238]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I cook most days of the week.\n",
      "Positive Inference 1: You cook regularly.\n",
      "tensor([[ 0.8294, -0.2900]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 0.8969, -0.4510]], grad_fn=<AddmmBackward>)\n",
      "Sample: I play as a power forward.\n",
      "Positive Inference 1: You play the power forward position in basketball.\n",
      "tensor([[ 0.1369, -0.3848]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You cook regularly.\n",
      "tensor([[ 0.6669, -0.7088]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[0.5993, 0.3809]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[ 1.5848, -0.0533]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I cook most days of the week.\n",
      "Positive Inference 1: You cook regularly.\n",
      "tensor([[ 0.8294, -0.2900]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 0.8969, -0.4510]], grad_fn=<AddmmBackward>)\n",
      "Sample: I play at least three times in a week\n",
      "Positive Inference 1: You play sport at least three times per week.\n",
      "tensor([[0.9439, 0.4020]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are an engineer.\n",
      "tensor([[1.6069, 0.1238]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am an engineer.\n",
      "Positive Inference 1: You are an engineer.\n",
      "tensor([[0.7278, 0.1604]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like musicals.\n",
      "tensor([[ 0.9711, -0.4817]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.500000\n",
      "####################\n",
      "20\n",
      "tensor(0.0620, grad_fn=<DivBackward0>)\n",
      "Sample: I am a software engineer.\n",
      "Positive Inference 1: You are a software engineer.\n",
      "tensor([[-0.1225,  1.1091]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't have a favourite author.\n",
      "tensor([[0.5355, 0.7341]], grad_fn=<AddmmBackward>)\n",
      "Sample: I used to play piano when I was a kid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Inference 1: You don't play an instrument.\n",
      "tensor([[-0.1662,  1.3178]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.3880, 0.7844]], grad_fn=<AddmmBackward>)\n",
      "Sample: I used to play piano when I was a kid.\n",
      "Positive Inference 1: You don't play an instrument.\n",
      "tensor([[-0.1662,  1.3178]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.3880, 0.7844]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[-0.2715,  1.3376]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[0.8438, 0.7285]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You like musicals.\n",
      "tensor([[0.5636, 0.7690]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[0.7246, 0.4579]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.3627,  1.9833]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[0.4442, 0.8306]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.3627,  1.9833]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[0.4442, 0.8306]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.3627,  1.9833]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[0.4442, 0.8306]], grad_fn=<AddmmBackward>)\n",
      "Sample: I own my own business.\n",
      "Positive Inference 1: You own your own business.\n",
      "tensor([[0.3223, 1.3101]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.3201, 1.0519]], grad_fn=<AddmmBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: You like to eat icecream.\n",
      "tensor([[0.3181, 0.9655]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You play sport at least three times per week.\n",
      "tensor([[0.5327, 0.8750]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.600000\n",
      "####################\n",
      "25\n",
      "tensor(0.0550, grad_fn=<DivBackward0>)\n",
      "Sample: I used to play piano when I was a kid.\n",
      "Positive Inference 1: You don't play an instrument.\n",
      "tensor([[0.3009, 0.9278]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.8903, 0.3544]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 0.5018, -0.0511]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[0.5234, 0.0744]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[0.0645, 1.0285]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[1.3643, 0.2788]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You like musicals.\n",
      "tensor([[0.8196, 0.5343]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[1.0801, 0.1317]], grad_fn=<AddmmBackward>)\n",
      "Sample: Three\n",
      "Positive Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[0.4530, 0.3163]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You really like the springtime.\n",
      "tensor([[ 0.5841, -0.2518]], grad_fn=<AddmmBackward>)\n",
      "Sample: I own my own business.\n",
      "Positive Inference 1: You own your own business.\n",
      "tensor([[0.7503, 0.8869]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.7672, 0.6350]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I go to the theatre regularly.\n",
      "Positive Inference 1: You like musicals.\n",
      "tensor([[0.8196, 0.5343]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[1.0801, 0.1317]], grad_fn=<AddmmBackward>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[ 0.5018, -0.0511]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[0.5234, 0.0744]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am a software engineer.\n",
      "Positive Inference 1: You are a software engineer.\n",
      "tensor([[0.2515, 0.8191]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't have a favourite author.\n",
      "tensor([[1.1238, 0.1991]], grad_fn=<AddmmBackward>)\n",
      "Sample: My favourite season is spring.\n",
      "Positive Inference 1: You really like the springtime.\n",
      "tensor([[0.1997, 0.3629]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[0.4064, 0.7122]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.700000\n",
      "####################\n",
      "30\n",
      "tensor(0.0515, grad_fn=<DivBackward0>)\n",
      "Sample: My favourite season is spring.\n",
      "Positive Inference 1: You really like the springtime.\n",
      "tensor([[0.1242, 0.4349]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[0.2834, 0.8202]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.0164,  1.7165]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[1.1992, 0.2055]], grad_fn=<AddmmBackward>)\n",
      "Sample: House music.\n",
      "Positive Inference 1: Your favourite style of music is house music.\n",
      "tensor([[0.0790, 1.2435]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[0.6783, 0.6802]], grad_fn=<AddmmBackward>)\n",
      "Sample: I don't have a favourite author.\n",
      "Positive Inference 1: You don't have a favourite author.\n",
      "tensor([[0.7611, 1.1715]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You cook regularly.\n",
      "tensor([[1.2292, 0.3928]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am a manager.\n",
      "Positive Inference 1: You are a manager.\n",
      "tensor([[-0.0555,  0.5616]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[ 0.8229, -0.3763]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I play the piano.\n",
      "Positive Inference 1: You play an instrument.\n",
      "tensor([[0.0304, 0.8169]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't play an instrument.\n",
      "tensor([[0.3958, 0.5120]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I play the piano.\n",
      "Positive Inference 1: You play an instrument.\n",
      "tensor([[0.0304, 0.8169]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't play an instrument.\n",
      "tensor([[0.3958, 0.5120]], grad_fn=<AddmmBackward>)\n",
      "Sample: Not really.\n",
      "Positive Inference 1: You do not like musicals.\n",
      "tensor([[0.6266, 0.0182]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[0.5986, 0.0674]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at a cafe.\n",
      "Positive Inference 1: You work at a cafe.\n",
      "tensor([[0.2761, 0.7350]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like musicals.\n",
      "tensor([[1.0761, 0.1002]], grad_fn=<AddmmBackward>)\n",
      "Sample: My favourite season is spring.\n",
      "Positive Inference 1: You really like the springtime.\n",
      "tensor([[0.1242, 0.4349]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[0.2834, 0.8202]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.700000\n",
      "####################\n",
      "35\n",
      "tensor(0.0482, grad_fn=<DivBackward0>)\n",
      "Sample: Two.\n",
      "Positive Inference 1: You think there are two players in a tennis match.\n",
      "tensor([[0.0387, 0.4031]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[0.0744, 0.5463]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am a lawyer.\n",
      "Positive Inference 1: You are a lawyer.\n",
      "tensor([[-0.1042,  0.9180]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You own your own business.\n",
      "tensor([[0.6997, 0.2331]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[-0.3344,  1.3632]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[1.3336, 0.3043]], grad_fn=<AddmmBackward>)\n",
      "Sample: Three\n",
      "Positive Inference 1: You think there are three players in a tennis match.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0097,  0.8370]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You really like the springtime.\n",
      "tensor([[0.2520, 0.1186]], grad_fn=<AddmmBackward>)\n",
      "Sample: Yes, I play the piano.\n",
      "Positive Inference 1: You play an instrument.\n",
      "tensor([[-0.1251,  0.9952]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't play an instrument.\n",
      "tensor([[0.2858, 0.6113]], grad_fn=<AddmmBackward>)\n",
      "Sample: My favourite season is spring.\n",
      "Positive Inference 1: You really like the springtime.\n",
      "tensor([[-0.0304,  0.5820]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[0.1887, 0.9380]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am a manager.\n",
      "Positive Inference 1: You are a manager.\n",
      "tensor([[-0.2189,  0.7060]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You do not like musicals.\n",
      "tensor([[ 0.7474, -0.3317]], grad_fn=<AddmmBackward>)\n",
      "Sample: I like to read the newspaper.\n",
      "Positive Inference 1: On the weekend, you like to read the newspaper.\n",
      "tensor([[0.0484, 1.2394]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You play the power forward position in basketball.\n",
      "tensor([[0.4008, 0.4203]], grad_fn=<AddmmBackward>)\n",
      "Sample: My favourite food is icecream\n",
      "Positive Inference 1: You like to eat icecream.\n",
      "tensor([[0.4593, 0.8780]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You play sport at least three times per week.\n",
      "tensor([[1.0242, 0.4381]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.1995,  1.8630]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[1.2689, 0.1510]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.800000\n",
      "####################\n",
      "40\n",
      "tensor(0.0457, grad_fn=<DivBackward0>)\n",
      "Sample: I own my own business.\n",
      "Positive Inference 1: You own your own business.\n",
      "tensor([[0.8681, 0.7196]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat fruit.\n",
      "tensor([[0.9377, 0.4219]], grad_fn=<AddmmBackward>)\n",
      "Sample: I like to eat fruit\n",
      "Positive Inference 1: You like to eat fruit.\n",
      "tensor([[0.9754, 0.5747]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You like to eat icecream.\n",
      "tensor([[1.0439, 0.7193]], grad_fn=<AddmmBackward>)\n",
      "Sample: Pizza.\n",
      "Positive Inference 1: Your favourite food is pizza.\n",
      "tensor([[0.1917, 1.2390]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: On the weekend, you like to read the newspaper.\n",
      "tensor([[1.4014, 0.3121]], grad_fn=<AddmmBackward>)\n",
      "Sample: I play as a power forward.\n",
      "Positive Inference 1: You play the power forward position in basketball.\n",
      "tensor([[-0.2084, -0.1094]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You cook regularly.\n",
      "tensor([[ 0.7381, -0.7857]], grad_fn=<AddmmBackward>)\n",
      "Sample: I am a software engineer.\n",
      "Positive Inference 1: You are a software engineer.\n",
      "tensor([[0.0243, 0.9543]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't have a favourite author.\n",
      "tensor([[ 1.3495, -0.0643]], grad_fn=<AddmmBackward>)\n",
      "Sample: Three\n",
      "Positive Inference 1: You think there are three players in a tennis match.\n",
      "tensor([[0.1522, 0.6852]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You really like the springtime.\n",
      "tensor([[ 0.5608, -0.1728]], grad_fn=<AddmmBackward>)\n",
      "Sample: House music.\n",
      "Positive Inference 1: Your favourite style of music is house music.\n",
      "tensor([[0.0335, 1.1972]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You are a lawyer.\n",
      "tensor([[0.9024, 0.4864]], grad_fn=<AddmmBackward>)\n",
      "Sample: I work at the tax department.\n",
      "Positive Inference 1: You work at the tax department.\n",
      "tensor([[-0.1662,  1.1307]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[ 1.6054, -0.0250]], grad_fn=<AddmmBackward>)\n",
      "Sample: I like to read the newspaper.\n",
      "Positive Inference 1: On the weekend, you like to read the newspaper.\n",
      "tensor([[0.1064, 1.1158]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You play the power forward position in basketball.\n",
      "tensor([[0.6683, 0.1325]], grad_fn=<AddmmBackward>)\n",
      "Sample: I've been in my current job for 3 years.\n",
      "Positive Inference 1: You've been working in your current job for three years.\n",
      "tensor([[-0.2280,  1.7787]], grad_fn=<AddmmBackward>)\n",
      "Negative Inference 1: You don't like your job.\n",
      "tensor([[ 1.5462, -0.1570]], grad_fn=<AddmmBackward>)\n",
      "Accuracy : 0.900000\n",
      "####################\n"
     ]
    }
   ],
   "source": [
    "class Classifier(torch.nn.Module):    \n",
    "    def __init__(self, esz=1536):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(\n",
    "            esz, esz,\n",
    "        )\n",
    "        self.out = torch.nn.Linear(\n",
    "            esz, 2,\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, input, hidden=None):\n",
    "        #return self.dense(input)\n",
    "        #return self.relu(self.dense(input))\n",
    "        return self.out(self.relu(self.dense(input)))\n",
    "\n",
    "class Attention(torch.nn.Module):    \n",
    "    def __init__(self, esz=768, seq_len=100):\n",
    "        super().__init__()\n",
    "        self.dense = torch.nn.Linear(\n",
    "            esz, 1\n",
    "        )        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.sm = torch.nn.Softmax()\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        return self.sm(self.dense(input))\n",
    "    \n",
    "class Model():\n",
    "    def __init__(self, lr=0.00005, esz=768, pad_len=20):\n",
    "        self.pad_len = pad_len\n",
    "        self.classifier = Classifier(esz=esz*2) \n",
    "        self.context_attention = Attention(esz=esz, seq_len=pad_len)\n",
    "        self.inference_attention = Attention(esz=esz, seq_len=pad_len)\n",
    "        self.utterance_attention = Attention(esz=esz, seq_len=pad_len)\n",
    "        self.optims = {\n",
    "            'classifier': optim.Adam(self.classifier.parameters(), lr=lr),\n",
    "            'context_attention': optim.Adam(self.context_attention.parameters(), lr=lr),\n",
    "            'inference_attention': optim.Adam(self.inference_attention.parameters(), lr=lr),\n",
    "            'utterance_attention': optim.Adam(self.utterance_attention.parameters(), lr=lr),\n",
    "        }\n",
    "        self.loss = 0\n",
    "        self.step = 0\n",
    "        self.c_loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    def update_params(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "            \n",
    "    def get_and_attend_context(self, embedded):\n",
    "        context_attention_mask1 = self.context_attention(embedded[\"context1\"])\n",
    "        context_attention_mask2 = self.context_attention(embedded[\"context2\"])\n",
    "        context = torch.sum((context_attention_mask1 * embedded[\"context1\"]) + (context_attention_mask2 * embedded[\"context2\"]), 1)\n",
    "        return context\n",
    "    \n",
    "    def attend_inference(self, inf):\n",
    "        inference_attention_mask = self.inference_attention(inf)\n",
    "        return torch.sum(inference_attention_mask * inf, 1)\n",
    "        #return inf.mean(1)\n",
    "\n",
    "    def attend_utterance(self, utterance):\n",
    "        utterance_attention_mask = self.utterance_attention(utterance)\n",
    "        return torch.sum(utterance_attention_mask * utterance, 1)\n",
    "        #return utterance.mean(1)\n",
    "    \n",
    "    def merge_utterance_with_inference_and_context(self, context, utterance, inference):\n",
    "        #return torch.cat([context,utterance,inference], 1)\n",
    "        return torch.cat([utterance,inference], 1)\n",
    "        \n",
    "    def eval_step(self):\n",
    "        self.classifier.eval()\n",
    "        self.context_attention.eval()\n",
    "        self.inference_attention.eval()\n",
    "        \n",
    "        accuracy = 0\n",
    "        num_steps = 10\n",
    "        for _ in range(num_steps):\n",
    "            xs = sample_test()\n",
    "            xs = sample_train()\n",
    "            print(\"Sample: %s\" % xs[\"sample1\"])\n",
    "            print(\"Positive Inference 1: %s\" % xs[\"inf1\"])\n",
    "            embedded = self.embed_sample(xs)\n",
    "            \n",
    "            context = self.get_and_attend_context(embedded)\n",
    "            inf1 = self.attend_inference(embedded[\"inf1\"])\n",
    "            utterance1 = self.attend_utterance(embedded[\"sample1\"])\n",
    "            merged_positive = self.merge_utterance_with_inference_and_context(context, utterance1, inf1)\n",
    "\n",
    "            pred = self.classifier(merged_positive) \n",
    "            print(pred)\n",
    "            pred = torch.argmax(pred, 1)\n",
    "            #if pred.item() == 0:\n",
    "                #print(\"Inference does not follow\")\n",
    "                #accuracy += .append(0)\n",
    "            if pred.item() == 1:\n",
    "                #print(\"Inference follows\")\n",
    "                accuracy += 1\n",
    "\n",
    "            inf_random = self.attend_inference(embedded[\"inf_random\"])\n",
    "            merged_negative = self.merge_utterance_with_inference_and_context(context, utterance1, inf_random)\n",
    "\n",
    "            print(\"Negative Inference 1: %s\" % xs[\"inf_random\"])\n",
    "            pred = self.classifier(merged_negative) \n",
    "            print(pred)\n",
    "            pred = torch.argmax(pred, 1)\n",
    "            \n",
    "            if pred.item() == 0:\n",
    "            #    print(\"Inference does not follow\")\n",
    "                #accuracy.append(1)\n",
    "                accuracy += 1\n",
    "            #else:\n",
    "                #accuracy.append(0)\n",
    "            #    print(\"Inference follows\")\n",
    "\n",
    "            #context = self.get_and_attend_context(embedded)\n",
    "            #inp = self.attend_inference_and_merge_context(embedded[\"inf1\"], context)\n",
    "        print(\"Accuracy : %f\" % (accuracy / (num_steps * 2)))\n",
    "        print(\"####################\")\n",
    "                \n",
    "    def embed_sample(self, xs):\n",
    "        embedded = {}\n",
    "        for k in [\"context1\",\"context2\",\"sample1\",\"sample2\",\"inf1\",\"inf2\",\"inf3\",\"inf_random\"]:\n",
    "            if k in xs and len(xs[k]) > 0:\n",
    "                tokens = tokenizer.encode(xs[k])\n",
    "                padded = torch.full((1, self.pad_len), tokenizer.pad_token_id, dtype=torch.long)\n",
    "                padded[0,:len(tokens)] = torch.LongTensor([tokens])\n",
    "                embedded[k] = encoder(padded)[0]\n",
    "        return embedded\n",
    "        \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.classifier.train()\n",
    "        self.context_attention.train()\n",
    "        self.inference_attention.train()\n",
    "        bsz = 50\n",
    "        batch_xs = []\n",
    "        batch_ys = []\n",
    "        for _ in range(bsz):\n",
    "            xs = sample_train()\n",
    "            #print(xs)\n",
    "            embedded = self.embed_sample(xs)\n",
    "            context = self.get_and_attend_context(embedded)\n",
    "            inf1 = self.attend_inference(embedded[\"inf1\"])\n",
    "            utterance1 = self.attend_utterance(embedded[\"sample1\"])\n",
    "            merged_positive = self.merge_utterance_with_inference_and_context(context, utterance1, inf1)\n",
    "            inf_random = self.attend_inference(embedded[\"inf_random\"])\n",
    "            merged_negative = self.merge_utterance_with_inference_and_context(context, utterance1, inf_random)\n",
    "            batch_xs.append(merged_positive)\n",
    "            batch_xs.append(merged_negative)\n",
    "            batch_ys.append([1])\n",
    "            batch_ys.append([0])\n",
    "        inp = torch.cat(batch_xs, 0).unsqueeze(1)\n",
    "        \n",
    "            #if \"inf2\" in embedded:\n",
    "            #    inf2 = self.attend_inference_and_merge_context(embedded[\"inf2\"], context)\n",
    "            #    inp = torch.cat([inp, inf2, inf_random], 0)\n",
    "            #    outs += [1,0]\n",
    "            #    if \"inf3\" in embedded:\n",
    "            #        inf3 = self.attend_inference_and_merge_context(embedded[\"inf3\"], context)\n",
    "            #        inp = torch.cat([inp, inf3, inf_random], 0)\n",
    "            #        outs += [1,0]\n",
    "        \n",
    "        outs = torch.LongTensor(batch_ys)\n",
    "        pred = self.classifier(inp)\n",
    "        loss = self.c_loss(torch.transpose(pred, 1, 2), outs)\n",
    "\n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % 5 == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.eval_step()\n",
    "\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "model = Model()\n",
    "for i in range(1000):\n",
    "    model.train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "with open(\"C:\\\\Users\\\\nickh\\\\OneDrive\\\\Desktop\\\\sequences.csv\") as csvDataFile:\n",
    "    csvreader = csv.reader(csvDataFile, delimiter='\\t')\n",
    "    next(csvreader)\n",
    "    for utterance, context, response in csvreader:\n",
    "        target = test_data if random.random() > 0.8 else train_data\n",
    "        target.append({\n",
    "            \"utterance\":utterance,\n",
    "            \"context\":context,\n",
    "            \"response\":response,\n",
    "        })\n",
    "\n",
    "def sample_train():\n",
    "    positive = random.choice(train_data)\n",
    "    while \"inf_random\" not in positive or positive[\"inf1\"] == positive[\"inf_random\"]:\n",
    "        negative = random.choice(train_data)\n",
    "        positive[\"inf_random\"] = negative[\"inf1\"]\n",
    "    return positive\n",
    "\n",
    "def sample_test():\n",
    "    positive = random.choice(test_data)\n",
    "    while \"inf_random\" not in positive or positive[\"inf1\"] == positive[\"inf_random\"]:\n",
    "        negative = random.choice(train_data)\n",
    "        positive[\"inf_random\"] = negative[\"inf1\"]\n",
    "    return positive\n",
    "\n",
    "class SequenceModel(Model):\n",
    "    def __init__(self, lr=0.0001, esz=768, pad_len=20):\n",
    "        super().init(self, lr, esz, pad_len)\n",
    "                    \n",
    "    def get_and_attend_context(self, embedded):\n",
    "        context_attention_mask = self.context_attention(embedded[\"context\"])\n",
    "        return context_attention_mask * embedded[\"context\"]\n",
    "\n",
    "    def embed_sample(self, xs):\n",
    "        embedded = {}\n",
    "        for k in [\"utterance\",\"context\",\"response\"]:\n",
    "            if k in xs and len(xs[k]) > 0:\n",
    "                tokens = tokenizer.encode(xs[k])\n",
    "                padded = torch.full((1, self.pad_len), tokenizer.pad_token_id, dtype=torch.long)\n",
    "                padded[0,:len(tokens)] = torch.LongTensor([tokens])\n",
    "                embedded[k] = encoder(padded)[0]\n",
    "        return embedded\n",
    "    \n",
    "    def eval_step(self):\n",
    "        self.classifier.eval()\n",
    "        self.context_attention.eval()\n",
    "        self.inference_attention.eval()\n",
    "        \n",
    "        accuracy = 0\n",
    "        num_steps = 10\n",
    "        for _ in range(num_steps):\n",
    "            xs = sample_test()\n",
    "            print(\"Sample: %s\" % xs[\"sample1\"])\n",
    "            print(\"Positive Inference 1: %s\" % xs[\"inf1\"])\n",
    "            embedded = self.embed_sample(xs)\n",
    "            \n",
    "            context = self.get_and_attend_context(embedded)\n",
    "            inf1 = self.attend_inference(embedded[\"inf1\"])\n",
    "            utterance1 = self.attend_inference(embedded[\"sample1\"])\n",
    "            merged_positive = self.merge_utterance_with_inference_and_context(context, utterance1, inf1)\n",
    "\n",
    "            pred = self.classifier(merged_positive) \n",
    "            print(pred)\n",
    "            pred = torch.argmax(pred, 1)\n",
    "            #if pred.item() == 0:\n",
    "                #print(\"Inference does not follow\")\n",
    "                #accuracy += .append(0)\n",
    "            if pred.item() == 1:\n",
    "                #print(\"Inference follows\")\n",
    "                accuracy += 1\n",
    "\n",
    "            inf_random = self.attend_inference(embedded[\"inf_random\"])\n",
    "            merged_negative = self.merge_utterance_with_inference_and_context(context, utterance1, inf_random)\n",
    "\n",
    "            pred = self.classifier(merged_negative) \n",
    "            \n",
    "            pred = torch.argmax(pred, 1)\n",
    "            print(\"Negative Inference 1: %s\" % xs[\"inf_random\"])\n",
    "            if pred.item() == 0:\n",
    "            #    print(\"Inference does not follow\")\n",
    "                #accuracy.append(1)\n",
    "                accuracy += 1\n",
    "            #else:\n",
    "                #accuracy.append(0)\n",
    "            #    print(\"Inference follows\")\n",
    "            print(pred)\n",
    "            #context = self.get_and_attend_context(embedded)\n",
    "            #inp = self.attend_inference_and_merge_context(embedded[\"inf1\"], context)\n",
    "        print(\"Accuracy : %f\" % (accuracy / num_steps))\n",
    "                        \n",
    "    def train_step(self):\n",
    "        loss = 0\n",
    "        self.zero_grad()\n",
    "        self.classifier.train()\n",
    "        self.context_attention.train()\n",
    "        self.inference_attention.train()\n",
    "\n",
    "        xs = sample_train()\n",
    "        \n",
    "        embedded = self.embed_sample(xs)\n",
    "        \n",
    "        context = self.get_and_attend_context(embedded)\n",
    "        response = self.attend_inference(embedded[\"response\"])\n",
    "        utterance1 = self.attend_inference(embedded[\"utterance\"])\n",
    "        merged_positive = self.merge_utterance_with_inference_and_context(context, utterance1, inf1)\n",
    "\n",
    "        \n",
    "        inf_random = self.attend_inference(embedded[\"inf_random\"])\n",
    "        merged_negative = self.merge_utterance_with_inference_and_context(context, utterance1, inf_random)\n",
    "        inp = torch.cat([merged_positive, merged_negative], 0).unsqueeze(1)\n",
    "        outs = [[1],[0]]\n",
    "        \n",
    "        #if \"inf2\" in embedded:\n",
    "        #    inf2 = self.attend_inference_and_merge_context(embedded[\"inf2\"], context)\n",
    "        #    inp = torch.cat([inp, inf2, inf_random], 0)\n",
    "        #    outs += [1,0]\n",
    "        #    if \"inf3\" in embedded:\n",
    "        #        inf3 = self.attend_inference_and_merge_context(embedded[\"inf3\"], context)\n",
    "        #        inp = torch.cat([inp, inf3, inf_random], 0)\n",
    "        #        outs += [1,0]\n",
    "        \n",
    "        outs = torch.LongTensor(outs)\n",
    "        #print(\"inp shape : %s\" % str(inp.size()))\n",
    "        #print(inp.size())\n",
    "        #print(inp)\n",
    "        pred = self.classifier(inp)\n",
    "        #print(pred)\n",
    "        #print(outs)\n",
    "        #print(\"pred shape : %s\" % str(pred.size()))\n",
    "        #print(\"outs shape : %s\" % str(outs.size()))\n",
    "        loss = self.c_loss(torch.transpose(pred, 1, 2), outs)\n",
    "\n",
    "        self.step += 1\n",
    "        self.loss += loss\n",
    "        if self.step % 5 == 0:\n",
    "            print(self.step)\n",
    "            print(self.loss / 50)\n",
    "            self.loss = 0\n",
    "            self.eval_step()\n",
    "\n",
    "        loss.backward()\n",
    "        self.update_params()\n",
    "model = Model()\n",
    "for i in range(1000):\n",
    "    model.train_step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
