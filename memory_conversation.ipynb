{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import random \n",
    "from pytorch_transformers.tokenization_distilbert import DistilBertTokenizer\n",
    "from pytorch_transformers.modeling_distilbert import DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "special_tokens_dict = {'additional_special_tokens': ['<PLH>', '<s>','</s>']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "encoder = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "pad_token = tokenizer.pad_token\n",
    "train_data = []\n",
    "test_data = []\n",
    "    \n",
    "with open(\"C:\\\\Users\\\\nickh\\\\Downloads\\\\memory_conversation.tsv\") as csvDataFile:\n",
    "    csvreader = csv.reader(csvDataFile, delimiter='\\t')\n",
    "    next(csvreader)\n",
    "    \n",
    "    data = []\n",
    "    conversation = {\n",
    "                \"conv_id\":None,\n",
    "                \"exchange_ids\":[],\n",
    "                \"user_responses\":[],\n",
    "                \"num_states\":0,\n",
    "                \"state_updates\":[],\n",
    "                \"agent_utterances\":[],\n",
    "                \"state_embeddings\":[]\n",
    "            }\n",
    "    max_states = 0\n",
    "    max_utterances = 0\n",
    "    \n",
    "    for conv_id, exchange_id, agent, user, action1, action2, action3 in csvreader:\n",
    "        if conversation[\"conv_id\"] is None:\n",
    "            conversation[\"conv_id\"] = conv_id\n",
    "        elif len(data) > 0 and conv_id != data[-1][\"conv_id\"]:\n",
    "            data.append(conversation)\n",
    "            max_utterances = max(\n",
    "                max_utterances, \n",
    "                len(conversation[\"exchange_ids\"])\n",
    "            )\n",
    "            conversation = {\n",
    "                \"conv_id\":conv_id,\n",
    "                \"exchange_ids\":[],\n",
    "                \"user_responses\":[],\n",
    "                \"num_states\":0,\n",
    "                \"state_updates\":[],\n",
    "                \"agent_utterances\":[],\n",
    "                \"state_embeddings\":[]\n",
    "            }\n",
    "        \n",
    "        conversation[\"agent_utterances\"].append(agent)\n",
    "        conversation[\"user_responses\"].append(user)\n",
    "        \n",
    "        state_updates = []\n",
    "        for action in (action1, action2, action3):\n",
    "            if action != \"NULL\":\n",
    "                tokenized_action = torch.LongTensor([\n",
    "                    tokenizer.encode(\n",
    "                        action.split(\", \")[1]\n",
    "                    )\n",
    "                ])\n",
    "                embedding = encoder(tokenized_action)[0]\n",
    "                idx = conversation[\"num_states\"]\n",
    "                conversation[\"num_states\"] += 1\n",
    "                state_updates.append((idx, embedding))\n",
    "        conversation[\"state_updates\"] = state_updates\n",
    "        conversation[\"exchange_ids\"].append(exchange_id)\n",
    "        max_states = max(max_states, len(conversation[\"exchange_ids\"]))\n",
    "    if len(conversation) > 0:\n",
    "        data.append(conversation)\n",
    "    max_utterances = max(\n",
    "        max_utterances, \n",
    "        len(conversation[\"agent_utterances\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(torch.nn.Module):\n",
    "    def __init__(self, esz=768, hsz=768):\n",
    "        super().__init__()\n",
    "        self.attn = torch.nn.MultiheadAttention(esz, 8)\n",
    "        \n",
    "    def forward(self, input, hidden=None):\n",
    "        attn_mask, _ = self.attn(input, input, input)\n",
    "        return torch.sum(input * attn_mask, 1)\n",
    "        \n",
    "class UtterancePredictor(torch.nn.Module):    \n",
    "    def __init__(self, esz=768, hsz=768):\n",
    "        super().__init__()\n",
    "        self.hsz = hsz\n",
    "        self.attn = torch.nn.MultiheadAttention(esz, 8)\n",
    "        self.dense = torch.nn.Linear(\n",
    "            esz, hsz,\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.out = torch.nn.Linear(\n",
    "            hsz, esz,\n",
    "        )\n",
    "    \n",
    "    # accepts seq_len x num_values  returns num_keys\n",
    "    def forward(self, input, hidden=None):\n",
    "        input = input.unsqueeze(0).unsqueeze(0)        \n",
    "        attended = input\n",
    "        out = self.out(self.relu(self.dense(attended)))\n",
    "        return out\n",
    "\n",
    "class StateUpdater(torch.nn.Module):\n",
    "    def __init__(self, num_values, hsz=768, esz=768):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dense = torch.nn.Linear(\n",
    "            num_values * 3, hsz,\n",
    "        )\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.out = torch.nn.Linear(\n",
    "            hsz, esz,\n",
    "        )\n",
    "        self.attn = torch.nn.MultiheadAttention(esz, 8)\n",
    "        \n",
    "    # accepts tuple of (num_keys x esz, esz x pad_len, esz x pad_len)  returns num_keys x esz\n",
    "    def forward(self, input, hidden=None):\n",
    "        state, agent, user = input\n",
    "        agent_attention, _ = self.attn(agent, agent, agent)\n",
    "        agent_attention = torch.sum(agent_attention * agent, 1)\n",
    "        #print(\"agent.size() : %s\" % str(agent.size()))\n",
    "        user_attention, _ = self.attn(user, user, user)\n",
    "        user_attention = torch.sum(user_attention * user, 1)\n",
    "        #print(\"user.size() : %s\" % str(user.size()))\n",
    "        dialog = torch.cat([agent_attention, user_attention], 1)\n",
    "        #print(\"dialog.size() : %s\" % str(dialog.size()))\n",
    "        dialog = dialog.repeat(state.size(0), 1)\n",
    "        \n",
    "        inp = torch.cat([state, dialog], 1)\n",
    "        return self.out(self.relu(self.dense(inp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 Loss 259.651855\n",
      "Evaluation Accuracy : 0.380952\n"
     ]
    }
   ],
   "source": [
    "class Model():\n",
    "    def __init__(self, lr=0.005, hsz=768, pad_len=20):\n",
    "        self.pad_len = pad_len\n",
    "        self.utterance_selector = UtterancePredictor()\n",
    "        self.state_updater = StateUpdater(hsz)\n",
    "        self.encoder_attention = Attention()\n",
    "        self.optims = {\n",
    "            'utterance_selector': optim.Adam(self.utterance_selector.parameters(), lr=lr),\n",
    "            'state_updater': optim.Adam(self.state_updater.parameters(), lr=lr),\n",
    "            'encoder_attention': optim.Adam(self.encoder_attention.parameters(), lr=lr),\n",
    "        }\n",
    "        self.loss = 0\n",
    "        self.step = 0\n",
    "        self.utterance_criterion = torch.nn.MSELoss()\n",
    "        self.state_criterion = torch.nn.MSELoss()\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "    def update_params(self):\n",
    "        for optimizer in self.optims.values():\n",
    "            optimizer.step()\n",
    "            \n",
    "    def encode(self, agent_utterance, user_response):\n",
    "        agent_utterance = random.choice(agent_utterance.split(\"|\"))\n",
    "        encoded = encoder(\n",
    "            torch.LongTensor(\n",
    "                [\n",
    "                    tokenizer.encode(\n",
    "                            \"[CLS] \" + agent_utterance + \" [SEP] \" + user_response\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        )[0]\n",
    "        return self.encoder_attention(encoded)\n",
    "    \n",
    "    def encode_option(self, i, conversation, utterance_matrix, dialog):\n",
    "        prefix = conversation[\"exchange_ids\"][i][:-1] \n",
    "        ids, utterances, responses = [], [], []\n",
    "        level = conversation[\"exchange_ids\"][i].count(\"_\")\n",
    "        while conversation[\"exchange_ids\"][i].count(\"_\") == level:\n",
    "            utterances.append(conversation[\"agent_utterances\"][i])\n",
    "            responses.append(conversation[\"user_responses\"][i])\n",
    "            ids.append(conversation[\"exchange_ids\"][i])\n",
    "            i += 1\n",
    "\n",
    "        idx = random.choice(range(len(ids)))\n",
    "        id = ids[idx]\n",
    "        utterances = [utterances[idx]]\n",
    "        responses = [responses[idx]]\n",
    "        \n",
    "#        print(\"Encoding %s\" % id)\n",
    "\n",
    "        utterance_encoded = self.encode(\n",
    "            utterances[0],\n",
    "            responses[0]\n",
    "        )\n",
    "        utterance_matrix.append((utterance_encoded + utterance_matrix[-1]) / 2)\n",
    "        \n",
    "        while prefix in conversation[\"exchange_ids\"][i]:\n",
    "            #print(\"Prefix %s in %s \" % (prefix,conversation[\"exchange_ids\"][i] ))\n",
    "            if id not in conversation[\"exchange_ids\"][i]:\n",
    "                #print(\"ID %s not in %s \" % (id,conversation[\"exchange_ids\"][i] ))\n",
    "                i += 1\n",
    "                continue\n",
    "            #print(\"ID %s IS in %s \" % (id,conversation[\"exchange_ids\"][i] ))\n",
    "\n",
    "            if conversation[\"exchange_ids\"][i].count(\"_\") == level + 1:\n",
    "                #print(\"Encoding conditional %s\" % (conversation[\"exchange_ids\"][i]))\n",
    "                utterances.append(conversation[\"agent_utterances\"][i])\n",
    "                responses.append(conversation[\"user_responses\"][i])\n",
    "                utterance_encoded = self.encode(\n",
    "                    utterances[-1], \n",
    "                    responses[-1]\n",
    "                )\n",
    "                utterance_matrix.append((utterance_encoded + utterance_matrix[-1]) / 2)\n",
    "                i += 1\n",
    "            elif conversation[\"exchange_ids\"][i].count(\"_\") == level + 2:\n",
    "                i = self.encode_option(i, conversation, utterance_matrix, dialog)\n",
    "            else:\n",
    "                raise Exception()\n",
    "        for j in range(len(utterances)):\n",
    "            dialog.append((utterances[j], responses[j]))\n",
    "        return i\n",
    "                        \n",
    "    def encode_utterance_matrix(self, conversation, esz=768):\n",
    "        dialog = []\n",
    "        utterance_matrix = []\n",
    "        i = 0\n",
    "        while i < len(conversation[\"exchange_ids\"]):\n",
    "            exchange_id = conversation[\"exchange_ids\"][i]\n",
    "            if not exchange_id.endswith(\"_A\"):\n",
    "                agent_utterance = conversation[\"agent_utterances\"][i]\n",
    "                user_response = conversation[\"user_responses\"][i]\n",
    "                dialog.append((agent_utterance, user_response))\n",
    "                utterance_encoded = self.encode(agent_utterance, user_response)\n",
    "                if i > 0:\n",
    "                    utterance_matrix.append((utterance_encoded + utterance_matrix[-1]) / 2)\n",
    "                else:\n",
    "                    utterance_matrix.append(utterance_encoded)\n",
    "                i += 1\n",
    "            else:\n",
    "                i = self.encode_option(i, conversation, utterance_matrix, dialog)\n",
    "\n",
    "        return torch.cat(utterance_matrix, 0), dialog\n",
    "   \n",
    "    def eval_step(self):\n",
    "        self.utterance_selector.eval()\n",
    "        self.state_updater.eval()\n",
    "        \n",
    "        accuracy = 0\n",
    "        \n",
    "        unset_token = tokenizer.encode(\"UNSET\")\n",
    "        unset_embedding = encoder(torch.LongTensor([unset_token]))[0].mean(1)\n",
    "        \n",
    "        conversation = random.choice(data)\n",
    "        utterance_matrix, dialog = self.encode_utterance_matrix(conversation)\n",
    "\n",
    "        # initialize state matrix with every entry set to \"UNSET\"\n",
    "        state_matrix = unset_embedding.repeat(conversation[\"num_states\"], 1)\n",
    "\n",
    "        for i in range(utterance_matrix.size(0) - 1):   \n",
    "            predicted_utterance = self.utterance_selector(utterance_matrix[i])\n",
    "            dists = torch.nn.PairwiseDistance()(predicted_utterance.squeeze(0), utterance_matrix[:,:768])\n",
    "            dists, indices = torch.min(dists, 0)\n",
    "            if dialog[i+1][0] == dialog[indices.item()][0]:\n",
    "                accuracy += 1\n",
    "            #print(\"Agent: %s User: %s\"  % (dialog[i][0], dialog[i][1]))\n",
    "            #print(\"Predicted Agent: %s\"  % (dialog[indices.item()][0]))\n",
    "            #print(\"Ground Agent: %s\"  % (dialog[i+1][0]))\n",
    "            #print(\"#####\")\n",
    "        print(\"Evaluation Accuracy : %f\" % (accuracy / (utterance_matrix.size(0) - 1)))\n",
    "        \n",
    "    def train_step(self):\n",
    "        \n",
    "        utterance_loss = None\n",
    "        state_loss = None\n",
    "\n",
    "        unset_token = tokenizer.encode(\"UNSET\")\n",
    "        unset_embedding = encoder(torch.LongTensor([unset_token]))[0].mean(1)\n",
    "        \n",
    "        # one conversation = one episode = one training loop iteration\n",
    "        loss = 0\n",
    "        for conversation in data:            \n",
    "            utterance_matrix, dialog = self.encode_utterance_matrix(conversation)\n",
    "\n",
    "            \n",
    "            # initialize state matrix with every entry set to \"UNSET\"\n",
    "            state_matrix = unset_embedding.repeat(conversation[\"num_states\"], 1)\n",
    "            \n",
    "            for i in range(utterance_matrix.size(0) - 1):\n",
    "                self.zero_grad()\n",
    "                self.utterance_selector.train()\n",
    "                self.state_updater.train()\n",
    "                \n",
    "                predicted_utterance = self.utterance_selector(utterance_matrix[i])\n",
    "                utterance_loss = self.utterance_criterion(\n",
    "                    predicted_utterance,\n",
    "                    utterance_matrix[i+1,:768]\n",
    "                )\n",
    "                                \n",
    "                if utterance_loss is not None:\n",
    "                    loss += utterance_loss\n",
    "                if state_loss is not None:\n",
    "                    loss += state_loss\n",
    "                \n",
    "            if loss > 0:\n",
    "                loss.backward()\n",
    "                self.update_params()\n",
    "            \n",
    "            self.step += 1\n",
    "            self.loss += loss\n",
    "            loss = 0\n",
    "            if self.step % 100 == 0:\n",
    "                print(\"Step %d Loss %f\" % (self.step, self.loss.item() / 50))\n",
    "\n",
    "                self.loss = 0\n",
    "                self.eval_step()\n",
    "\n",
    "model = Model()\n",
    "for i in range(1000):\n",
    "    model.train_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = [\n",
    "    \n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
